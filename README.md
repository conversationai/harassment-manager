# Harassment Manager

Online abuse and harassment silence important voices in conversation, forcing
already marginalized people offline.

**Harassment Manager** is a web application that aims to empower users to
document and take action on abuse targeted at them on online platforms. It is
designed for anyone that experiences significant online harassment, which can be
episodic or an ongoing challenge. The tool has been built and tested using a
community based research and design process with active Twitter users that
experience significant and/or frequent harassment (more details about our
research process and published results are available on
[Arxiv](https://arxiv.org/abs/2202.11168)). Target users include folks who are
disproportionately impacted by online harassment such as women and other
marginalized groups, journalists, activists, and politicians.

This web app was built by [Jigsaw](http://jigsaw.google.com), a unit within
Google that explores threats to open societies and builds technology that
inspires scalable solutions, in collaboration with Twitter. To detect
potentially harmful comments, it uses Jigsaw’s [Perspective
API](http://www.perspectiveapi.com), which uses machine learning to identify
“toxic” language. We define toxicity as language that is rude, disrespectful or
likely to make someone read a conversation. You can read our [model
cards](https://developers.perspectiveapi.com/s/about-the-api-model-cards) to
learn more about how our machine learning models are trained.

## Development

- [Setup](docs/1_setup.md) contains a technical overview of the application and
  how to set up dependencies
- [Development](docs/2_development.md) covers how to set up a local environment
  for development
- [Deployment](docs/3_deployment.md) contains instructions on how to deploy the
  application

## Support

For any technical issues, please create an issue in this repository. For
additional support and to contact us, see
https://developers.perspectiveapi.com/s/contact-us.
